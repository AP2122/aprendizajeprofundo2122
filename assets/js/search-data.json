{
  
    
        "post0": {
            "title": "Segmentación semántica",
            "content": "En este notebook se muestra cómo crear un modelo de segmentación semántica usando la arquitectura U-net incluida en la librería FastAI. . En esta práctica vamos a hacer un uso intensivo de la GPU, así que es importante activar su uso desde la opción Configuración del cuaderno del menú Editar (esta opción debería estar habilitada por defecto, pero es recomendable que lo compruebes). . Librer&#237;as . Comenzamos actualizando la librería FastAI. Al finalizar la instalación deberás reiniciar el kernel (menú Entorno de ejecución -&gt; Reiniciar Entorno de ejecución). . !pip install fastai -Uq . Cargamos a continuación las librerías que necesitaremos en esta práctica. . from fastai.basics import * from fastai.vision import models from fastai.vision.all import * from fastai.metrics import * from fastai.data.all import * from fastai.callback import * from pathlib import Path import random . Dataset . Para esta práctica vamos a usar como dataset el proporcionado en el trabajo Deep neural networks for grape bunch segmentation in natural images from a consumer‑grade camera. Este dataset dedicado a la segmentación de racimos de uva consta de 66 imágenes de entrenamiento y 14 de test con 5 categorías: background, leaves, wood, pole, y grape. Los siguientes comandos descargan y descomprimen dicho dataset. En este notebook vamos a usar solo dos clases: background y grape. . %%capture !wget https://www.dropbox.com/s/uknzc914w311web/dataset.zip?dl=1 -O dataset.zip !unzip dataset.zip . Vamos a explorar el contenido de este dataset. Para ello vamos a crear un objeto Path que apunta al directorio que acabamos de crear. . path=Path(&#39;dataset/&#39;) . Como en la práctica anterior, podemos ver el contenido de este directorio usando el comando ls(). . path.ls() . Si exploráis el directorio podréis ver que hay dos carpetas llamadas Images y Labels. La carpeta Images contiene las imágenes del dataset, y la carpeta Labels contiene las en forma de máscara. Para cada imagen, hay un fichero de anotación siguiendo la siguiente nomenclatura: si la imagen se llama color_xxx.jpg, su fichero de anotación es gt_xxx.png. El dataset está partido en entrenamiento y test como puede verse en las carpetas Images y Labels. Además, se proporcionan dos ficheros txt que van a contener las clases de los objetos que utilizaremos en esta práctica. El fichero codes.txt contiene solo dos clases (background y grape), mientras que el fichero codesAll.txt contiene todas las posibles clases. . (path/&#39;Images&#39;).ls() . (path/&#39;Images/train&#39;).ls() . (path/&#39;Labels/train&#39;).ls() . Definiciones previas . El proceso para entrenar nuestro modelo va a ser similar al visto en la práctica 1 para crear un modelo de clasificación. Sin embargo, para cargar nuestro dataset será necesario dar unas definiciones previas. Estas definiciones son necesarias para ajustar la carga del datos a la estructura de nuestro dataset. . En primer lugar vamos a definir los paths donde se van a encontrar nuestras imágenes y sus etiquetas. . path_images = path/&quot;Images&quot; path_labels = path/&quot;Labels&quot; . A continuación definimos el nombre que va a tener nuestra carpeta de test. . test_name = &quot;test&quot; . Seguidamente definimos una función que dado el path de una imagen nos devuelve el path de su anotación. . def get_y_fn (x): return Path(str(x).replace(&quot;Images&quot;,&quot;Labels&quot;).replace(&quot;color&quot;,&quot;gt&quot;).replace(&quot;.jpg&quot;,&quot;.png&quot;)) . Seguidamente cargamos las clases que pueden tener los píxeles de nuestra imágenes y lo almacenamos en una lista codes. . codes = np.loadtxt(path/&#39;codes.txt&#39;, dtype=str) . codes . Podemos ahora ver alguna de las imágenes de nuestro dataset. . img_f = path_images/&#39;train/color_206.jpg&#39; img = PILImage.create(img_f) img.show(figsize=(5, 5)) . Y también la anotación asociada. . mask = PILMask.create(get_y_fn(img_f)) mask.show(figsize=(5, 5), alpha=1) . Como podemos ver en la imagen anterior tenemos una máscara donde cada tipo de objeto de nuestra imagen tiene un color distinto. . Partici&#243;n del dataset . Como en cualquier problema de machine learning debemos partir nuestro dataset en entrenamiento y test. En nuestro caso los datos ya están separados por lo que vamos a definir una función que nos permite diferenciarlos gracias a la estructura de carpetas que usamos. . def ParentSplitter(x): return Path(x).parent.name==test_name . Data augmentation . Al igual que con los modelos definidos en prácticas anteriores podemos usar técnicas de aumento de datos, para lo que usaremos la librería Albumentations. Recordar que dichas transformaciones no deben aplicarse solo a la imagen sino también a su anotación. Para ello vamos a definir una clase que hereda de la clase ItemTransform y que nos va a permitir realizar transformaciones sobre pares (imagen,máscara). . La clase ItemTransform tiene un método encodes que es el encargado de realizar la transformación sobre su entrada x que en este caso será un par (imagen,máscara). Además el constructor de la clase que vamos a definir recibirá como parámetro las transformaciones a aplicar. . from albumentations import ( Compose, OneOf, ElasticTransform, GridDistortion, OpticalDistortion, HorizontalFlip, Rotate, Transpose, CLAHE, ShiftScaleRotate ) class SegmentationAlbumentationsTransform(ItemTransform): split_idx = 0 def __init__(self, aug): self.aug = aug def encodes(self, x): img,mask = x aug = self.aug(image=np.array(img), mask=np.array(mask)) return PILImage.create(aug[&quot;image&quot;]), PILMask.create(aug[&quot;mask&quot;]) . En nuestro caso vamos a utilizar solo flips horizontales, rotaciones, y una operación que aplica una pequeña distorsión a la imagen. Dichas transformaciones se aplicarán de manera secuencia y de manera aleatoria. . transforms=Compose([HorizontalFlip(p=0.5), Rotate(p=0.40,limit=10),GridDistortion() ],p=1) . Por último construimos un objeto de la clase definida anteriormente. . transformPipeline=SegmentationAlbumentationsTransform(transforms) . También va a ser necesario realizar una transformación adicional sobre las máscaras. Las máscaras contienen píxeles con 7 valores distintos (255: grape, 150: leaves, 76: pole, 74: pole, 29: wood, 25: wood, 0: background). Como vamos a trabajar únicamente con las clases grape y background, los píxeles del resto de clases deberán estar a 0 (es decir los vamos a considerar como background). Además, los números de las clases deben ser 0,1,2,... Es por esto que es necesario cambiar todos los píxeles con valor 255 a valor 1. Para realizar estas transformaciones definimos la siguiente clase. . class TargetMaskConvertTransform(ItemTransform): def __init__(self): pass def encodes(self, x): img,mask = x #Convert to array mask = np.array(mask) mask[mask!=255]=0 # Change 255 for 1 mask[mask==255]=1 # Back to PILMask mask = PILMask.create(mask) return img, mask . Dataloader . Ya estamos listos para definir nuestro DataBlock y seguidamente nuestro DataLoader. Nuestro DataBlock se define del siguiente modo. . trainDB = DataBlock(blocks=(ImageBlock, MaskBlock(codes)), get_items=partial(get_image_files,folders=[&#39;train&#39;]), get_y=get_y_fn, splitter=RandomSplitter(valid_pct=0.2), item_tfms=[Resize((480,640)), TargetMaskConvertTransform(), transformPipeline], batch_tfms=Normalize.from_stats(*imagenet_stats) ) . Vamos a explicar cada una de las componentes anteriores: . blocks=(ImageBlock, MaskBlock(codes)). En este caso tenemos que la entrada de nuestro modelo va a ser una imagen (representada mediante un ImageBlock) y su salida es una máscara (representado mediante MaskBlock) cuyos posibles valores son aquellos proporcionados por la lista de clases almacenada en la variable codes. | get_items=partial(get_image_files,folders=[&#39;train&#39;]). El parámetro get_items sirve para indicar cómo cargar los datos de nuestro dataset. Para esto vamos a usar la función get_image_files que devuelve los paths de las imágenes que se encuentran dentro de la carpeta folders (en nuestro caso la carpeta train). | get_y=get_y_fn. El parámetro get_y sirve para indicar cómo obtener la anotación asociada con una entrada (recordar que una entrada va a ser una imagen definida a partir de su path). Para esto tenemos la función get_y_fn definida anteriormente. | splitter=RandomSplitter(valid_pct=0.2). Como siempre debemos partir nuestro dataset para tener un conjunto de validación de cara a seleccionar nuestros hiperparámetros. En este caso partimos el conjunto de entrenamiento usando un porcentaje 80/20. | item_tfms=[Resize((480,640)), TargetMaskConvertTransform(), transformPipeline]. En el parámetro item_tfms indicamos las transformaciones que vamos a aplicar a nuestras imágenes y sus correspondientes máscaras. Además de las explicadas anteriormente vamos a reescalar las imágenes al tamaño 480x640. | batch_tfms=Normalize.from_stats(*imagenet_stats). En el parámetro batch_tfms indicamos las transformaciones que se realizan a nivel de batch. En este caso como en nuestro modelo utilizaremos un backbone preentrenado en ImageNet debemos normalizar las imágenes para que tengan la escala de esas imágenes. | . Con las explicaciones anteriores en sencillo comprender como definimos el siguiente DataBlock que nos servirá para evaluar nuestros modelos en el conjunto de test. . testDB = DataBlock(blocks=(ImageBlock, MaskBlock(codes)), get_items=partial(get_image_files,folders=[&#39;train&#39;,&#39;test&#39;]), get_y=get_y_fn, splitter=FuncSplitter(ParentSplitter), item_tfms=[Resize((480,640)), TargetMaskConvertTransform(), transformPipeline], batch_tfms=Normalize.from_stats(*imagenet_stats) ) . Ahora ya podemos definir nuestros Dataloaders indicando el path donde se encuentran las imágenes y el batch size que vamos a utilizar. . bs = 4 trainDLS = trainDB.dataloaders(path_images,bs=bs) testDLS = testDB.dataloaders(path_images,bs=bs) . Como siempre es conveniente mostrar un batch para comprobar que se están cargando los datos correctamente. . trainDLS.show_batch(vmin=0,vmax=1,figsize=(12, 9)) . Definici&#243;n de modelo . Ya podemos definir nuestro modelo y entrenarlo como hemos hecho en prácticas anteriores. Para ello vamos a crear un Learner mediante la función unet_learner a la cual le tenemos que proporcionar el DataLoader el backbone que vamos a utilizar (en este caso usaremos un modelo Resnet-18) y las métricas Dice y Jaccard que emplearemos para evaluar nuestro modelo. . learn = unet_learner(trainDLS,resnet18,metrics=[Dice(),JaccardCoeff()]).to_fp16() . Por último entrenamos nuestro modelo. . learn.fit_one_cycle(20,3e-3) . Una vez entrenado el modelo lo vamos a guardar para usarlo posteriormente. Lo primero que hacemos es extraer el modelo del Learner y caragarlo en la CPU. . aux=learn.model aux=aux.cpu() . Ahora vamos a guardarlo, para lo cual es necesario cargar una imagen que le servirá como referencia para realizar las transformaciones necesarias. Para ello es necesario normalizar la imagen para que sigan el estándar de ImageNet. . import torchvision.transforms as transforms img = PILImage.create(path_images/&#39;train/color_206.jpg&#39;) transformer=transforms.Compose([transforms.Resize((480,640)), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) img=transformer(img).unsqueeze(0) img=img.cpu() traced_cell=torch.jit.trace(aux, (img)) traced_cell.save(&quot;unet.pth&quot;) . Evaluando el modelo . Al igual que vimos para los modelos de clasificación, la métrica mostrada durante el proceso de entrenamiento se refiere al conjunto de validación, mientras que nos interesa saber el resultado obtenido para el conjunto de test. . Para ello debemos modificar el dataloader del objeto Learn que hemos entrenado anteriormente. . learn.dls = testDLS . Por último evaluamos nuestro modelo usando el método validate(). En este caso el método validate() devuelve tres valores, el valor de la pérdida, y el valor de las métricas definidas anteriormente con respecto al conjunto de test. . learn.validate() . Inferencia . Vamos a ver cómo usar el modelo ante una nueva imagen. Para ello lo primero que vamos a hacer es cargar el modelo. El modelo inicialmente lo cargaremos en la CPU, pero posteriormente si hay una GPU disponible la usaremos para inferencia. . device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) model = torch.jit.load(&quot;unet.pth&quot;) model = model.cpu() model.eval() . El siguiente paso es cargar la imagen, para lo que usaremos la librería PIL. . import PIL . img = PIL.Image.open(&#39;dataset/Images/test/color_154.jpg&#39;) . La siguiente instrucción permite mostrar la imagen que acabamos de cargar. . img . Ya estaríamos listos para relizar las predicciones sobre la imagen. Sin embargo, cabe recordar que primero debemos reescalar las imágenes y normalizarlas. . import torchvision.transforms as transforms def transform_image(image): my_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image_aux = image return my_transforms(image_aux).unsqueeze(0).to(device) . El siguiente paso consiste en transformar la imagen. . image = transforms.Resize((480,640))(img) tensor = transform_image(image=image) . Ahora ya podemos realizar pasarle el objeto construido anteriormente al modelo para realizar la predicción. . model.to(device) with torch.no_grad(): outputs = model(tensor) outputs = torch.argmax(outputs,1) . Ahora almacenamos el resultado en un array y convertimos el índice asociado con la clase grape (que era 1) al valor 255. . mask = np.array(outputs.cpu()) mask[mask==1]=255 . La predicción devuelta por el modelo es un vector de tamaño 480x640 por lo que tendremos que ponerla en forma de matriz. . mask=np.reshape(mask,(480,640)) . Con esto ya podemos mostrar la máscara generada. . Image.fromarray(mask.astype(&#39;uint8&#39;)) . Podemos compararla con la máscara real. . PIL.Image.open(&#39;dataset/Labels/test/gt_154.png&#39;) . Como vemos el modelo se aproxima bastante, pero la segmentación no es excesivamente buena. En la práctica veremos cómo crear mejores modelos. .",
            "url": "https://ap2122.github.io/aprendizajeprofundo2122/practica/2022/02/22/practica3-segmentacion-semantica.html",
            "relUrl": "/practica/2022/02/22/practica3-segmentacion-semantica.html",
            "date": " • Feb 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Detector de objetos",
            "content": "En este notebook se muestra cómo crear un modelo de detección de objetos usando la arquitectura Faster R-CNN. Para crear nuestro modelo vamos a utilizar la librería IceVision que es una librería para crear modelos de detección usando FastAI. . En esta práctica vamos a hacer un uso intensivo de la GPU, así que es importante activar su uso desde la opción Configuración del cuaderno del menú Editar (esta opción debería estar habilitada por defecto, pero es recomendable que lo compruebes). . Librer&#237;as . Comenzamos descargando la librería IceVision. Al finalizar la instalación deberás reiniciar el kernel (menú Entorno de ejecución -&gt; Reiniciar Entorno de ejecución). . !pip install icevision[all] -Uq . A continuación, cargamos aquellas librerías que son necesarias. . from icevision.all import * . Dataset . Para esta práctica vamos a usar como ejemplo el Fruit Images for Object Detection dataset. Este dataset consta de 240 imágenes de entrenamiento y 60 de test con tres categorías: manzanas, plátanos y naranjas. Los siguientes comandos descargan y descomprimen dicho dataset. . %%capture !wget https://www.dropbox.com/s/1dsfd5rrmg3riqj/fruits.zip?dl=1 -O fruits.zip !unzip fruits.zip . Vamos a explorar el contenido de este dataset. Para ello vamos a crear un objeto Path que apunta al directorio que acabamos de crear. . path=Path(&#39;fruits&#39;) . Como en la práctica anterior, podemos ver el contenido de este directorio usando el comando ls(). . path.ls() . Si exploráis el directorio podréis ver que hay dos carpetas (llamadas train y test), y que cada una de ellas contiene dos carpetas, llamadas images y labels. La carpeta images contiene las imágenes del dataset, y la carpeta labels contiene las anotaciones en formato Pascal VOC. Para cada imagen, hay un fichero xml con el mismo nombre que contiene su extensión. . Icevision . El proceso para crear y evaluar un modelo de IceVision consta de los siguientes pasos: . Crear un parser para leer las imágenes y las anotaciones. | Construir objetos record a partir de los parser. | Crear los datasets a partir de los records y los aumentos que queramos aplicar. | Crear un dataloader a partir de los datasets. | Definir un modelo. | Entrenar el modelo. | Guardar el modelo. | Usar el modelo para inferencia | Vamos a ver en detalle cada uno de estos pasos. . Parser . IceVision proporciona una serie de parsers definidos por defecto para leer las anotaciones en distintos formatos entre ellos Pascal VOC y COCO. También es posible crear parsers propios. A pesar de que existe un parser para el formato de nuestra anotación, vamos a ver cómo crear un parser desde cero. . El primer paso es crear una plantilla para nuestro dataset. . template_record = ObjectDetectionRecord() . A continuación IceVision proporciona el método generate_template que nos proporciona los métodos que debemos implementar. . Parser.generate_template(template_record) . A continuación vamos a implementar nuestra clase con cada uno de esos métodos. . import xml.etree.ElementTree as ET class MyParser(Parser): &quot;&quot;&quot;Definimos el constructor de nuestra clase que va a recibir cuatro parámetros: - La plantilla definida previamente. - El path al directorio donde se encuentran las imágenes. - El path al directorio donde se encuentran las anotaciones. - Un objeto class_map con las clases que tiene nuestro dataset. &quot;&quot;&quot; def __init__(self, template_record,path_img,path_anotaciones,class_map): super().__init__(template_record=template_record) self.path_img = path_img self.path_anotaciones= path_anotaciones self.class_map = class_map &quot;&quot;&quot;El método iter escanea el directorio de anotaciones y nos devuelve el nombre de cada fichero. Dicho nombre será utilizado por el resto de método&quot;&quot;&quot; def __iter__(self): with os.scandir(self.path_anotaciones) as ficheros: for fichero in ficheros: yield fichero.name &quot;&quot;&quot;El método len nos indica el número de elementos de los que consta nuestro dataset&quot;&quot;&quot; def __len__(self): return len(self.path_anotaciones) &quot;&quot;&quot;A partir del nombre del fichero de anotación, record_id debe devolver el identificador (o nombre) de la imagen asociada&quot;&quot;&quot; def record_id(self, o) -&gt; Hashable: #o --&gt; nombre de la anotación return o[:o.find(&#39;.&#39;)] &quot;&quot;&quot;A continuación deberíamos definir el método parse_fields, pero vamos a definir una serie de definiciones previas que nos serán útiles&quot;&quot;&quot; &quot;&quot;&quot;El método prepare recibe el nombre de un fichero de anotación como parámetro y realiza una serie de labores de preprocesamiento sobre dicho fichero de anotación. En este caso lo procesa usando la funcionalidad de la librería para trabajar con xml&quot;&quot;&quot; def prepare(self, o): tree = ET.parse(str(self.path_anotaciones)+&#39;/&#39;+str(o)) self._root = tree.getroot() &quot;&quot;&quot;El método filepath a partir del nombre del fichero de anotación devuelve el path de la imagen asociada&quot;&quot;&quot; def filepath(self, o) -&gt; Union[str, Path]: path=Path(f&quot;{o[:o.find(&#39;.&#39;)]}.jpg&quot;) return self.path_img / path &quot;&quot;&quot;La función image_width_height devuelve el ancho y el alto de una imagen a partir del nombre del fichero de anotación&quot;&quot;&quot; def image_width_height(self, o) -&gt; Tuple[int, int]: return get_img_size(str(self.path_img)+&#39;/&#39;+f&quot;{o[:o.find(&#39;.&#39;)]}.jpg&quot;) &quot;&quot;&quot;La función labels recibe el nombre del fichero de anotación y debe devolver una lista con los identificadores de las clases contenidas en dicho fichero.&quot;&quot;&quot; def labels(self, o) -&gt; List[int]: labels = [] for object in self._root.iter(&quot;object&quot;): label = object.find(&quot;name&quot;).text label_id = self.class_map.get_by_name(label) labels.append(label) return labels &quot;&quot;&quot;La función bboxes recibe el nombre del fichero de anotación y debe devolver una lista de bboxes que son las anotaciones contenidas en dicho fichero. El formato de cada BBOX es xmin, ymin, xmax, ymax.&quot;&quot;&quot; def bboxes(self, o) -&gt; List[BBox]: def to_int(x): return int(float(x)) bboxes = [] for object in self._root.iter(&quot;object&quot;): xml_bbox = object.find(&quot;bndbox&quot;) xmin = to_int(xml_bbox.find(&quot;xmin&quot;).text) ymin = to_int(xml_bbox.find(&quot;ymin&quot;).text) xmax = to_int(xml_bbox.find(&quot;xmax&quot;).text) ymax = to_int(xml_bbox.find(&quot;ymax&quot;).text) bbox = BBox.from_xyxy(xmin, ymin, xmax, ymax) bboxes.append(bbox) return bboxes &quot;&quot;&quot;Definimos a continuación el método parse_fields para cada elemento de nuestro dataset proporcionamos: - El path a la imagen. - El tamaño de la imagen. - El mapa de clases. - Los rectángulos que indican cada uno de los objetos de la imagen. - Las etiquetas de cada uno de los objetos de la imagen.&quot;&quot;&quot; def parse_fields(self, o: Any, record: BaseRecord, is_new: bool): self.prepare(o) if is_new: record.set_filepath(self.filepath(o)) record.set_img_size(self.image_width_height(o)) record.detection.set_class_map(self.class_map) record.detection.add_bboxes(self.bboxes(o)) record.detection.add_labels(self.labels(o)) . Una vez que hemos definido nuestra clase para parsear las anotaciones de nuestro dataset, vamos a construir los objetos correspondientes. . Lo primero que tenemos que hacer es construir nuestro class_map que es un objeto de la clase ClassMap y que contiene las clases de objetos de nuestro dataset. . class_map = ClassMap([&#39;apple&#39;,&#39;banana&#39;,&#39;orange&#39;]) . A continuación definimos nuestros parsers. Uno para leer el conjunto de entrenamiento, y otro para el de test. . trainPath = Path(&#39;fruits&#39;)/&#39;train&#39; parserTrain = MyParser(template_record, trainPath/&#39;images&#39;, trainPath/&#39;labels&#39;, class_map) testPath = Path(&#39;fruits&#39;)/&#39;test&#39; parserTest = MyParser(template_record,testPath/&#39;images&#39;, testPath/&#39;labels&#39;, class_map) . Records . Un record es un diccionario que contiene todos los campos parseados definidos en el proceso anterior. Mientras que cada parser es específico para cada anotación concreta, los objetos record tienen una estructura común. Para construir los records a partir de nuestros objetos parser debemos llamar al método parse e indicarle cómo se van a repartir los datos que se lean. . Como siempre, vamos a dividir nuestro dataset en tres partes: un conjunto de entrenamiento, uno de validación y uno de test. Por lo tanto tendremos que construir tres records llamados train_records, valid_records y test_records. Los records de entrenamiento y validación los construiremos a partir de los datos de entrenamiento usando una partición 90/10. Mientras que el record de test se construye a partir del conjunto de test usándolo completamente. . train_records, valid_records = parserTrain.parse(RandomSplitter((0.9, 0.1))) test_records,_= parserTest.parse(RandomSplitter((1.0, 0.0))) . Transforms . Las transformaciones o aumentos son una parte fundamental cuando estamos construyendo modelos en visión por computador. IceVision incluye por defecto la librería Albumentations que nos proporciona una gran cantidad de transformaciones. Además es capaz de gestionar los cambios en la anotación que son necesarios cuando se trabaja en detección de objetos. . IceVision proporciona una función muy útil que es tfms.A.aug_tfms con una gran cantidad de transformaciones. Además podemos añadirle cualquier otra transformación de Albumentations. . Para nuestro ejemplo vamos a usar las transformaciones sugeridas por defecto por IceVision y aplicar la técnica de presizing vista para clasificación de imágenes; además será necesario normalizar las imágenes al rango de las imágenes de ImageNet. Notar que las transformaciones se aplicarán solo al conjunto de entrenamiento. Para los conjuntos de validación y test únicamente tendremos que escalar la imagen al tamaño adecuado y normalizarla. . presize = 512 size = 384 . train_tfms = tfms.A.Adapter( [*tfms.A.aug_tfms(size=size, presize=presize), tfms.A.Normalize()] ) valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size), tfms.A.Normalize()]) . Dataset . La clase Dataset sirve para combinar los records y las transformaciones. Debemos crear un dataset para nuestro conjunto de entrenamiento, otro para el conjunto de validación y otro para el de test. . train_ds = Dataset(train_records, train_tfms) valid_ds = Dataset(valid_records, valid_tfms) test_ds = Dataset(test_records, valid_tfms) . Una vez creados dichos datasets podemos mostrar imágenes de los mismos. En concreto la siguiente instrucción muestra imágenes del conjunto de entrenamiento a las cuáles se les han aplicado una serie de transformaciones. Es conveniente ejecutar esta visualización para comprobar que todo está correcto. . samples = [train_ds[0] for _ in range(3)] show_samples(samples, ncols=3, class_map=class_map, denormalize_fn=denormalize_imagenet) . DataLoaders . Al igual que vimos para los modelos de clasificación de FastAI, el último paso es crear nuestros DataLoaders a partir de los datasets construidos anteriormente. Notar que cada modelo tiene su propio DataLoader. En este caso como vamos a crear un modelo de Faster RCNN debemos usar las siguientes instrucciones. . train_dl = models.torchvision.faster_rcnn.train_dl(train_ds, batch_size=8, num_workers=0, shuffle=True) valid_dl = models.torchvision.faster_rcnn.valid_dl(valid_ds, batch_size=8, num_workers=0, shuffle=False) test_dl = models.torchvision.faster_rcnn.valid_dl(test_ds, batch_size=8, num_workers=0, shuffle=False) . Entrenando el modelo . Para crear y entrenar nuestro modelo debemos crear un objeto Learner de FastAI. Para crear dicho objeto, lo primero que debemos hacer es construir un modelo con la arquitectura que queremos usar, en este caso Faster RCNN y con un backbone que es Resnet18. . model = models.torchvision.faster_rcnn.model(backbone=models.torchvision.faster_rcnn.backbones.resnet18_fpn(pretrained=True), num_classes=len(class_map)) . A continuación debemos proporcionar las métricas que queremos utilizar para evaluar el modelo. Por el momento la única métrica soportada por IceVision es el mAP de COCO, por lo tanto utilizaremos dicha métrica. . metrics = [COCOMetric(metric_type=COCOMetricType.bbox)] . Ya estamos listos para construir nuestro Learner. Notar que dicho objeto se construye de manera distinta dependiendo de la arquitectura que queramos utilizar. . learn = models.torchvision.faster_rcnn.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics) . Ahora podemos entrenar nuestro modelo utilizando la técnica de fine tuning que vimos en clase. . learn.fine_tune(10,freeze_epochs=2) . Una vez finalizado el entrenamiento podemos guardar nuestro modelo del siguiente modo. . torch.save(model.state_dict(),&#39;fasterRCNNFruits.pth&#39;) . Evaluando el modelo . Al igual que vimos para los modelos de clasificación, la métrica mostrada durante el proceso de entrenamiento se refiere al conjunto de validación, mientras que nos interesa saber el resultado obtenido para el conjunto de test. . Para ello, lo primero que debemos hacer es construir un nuevo dataloader del siguiente modo, indicando que el conjunto de validación es el de test. . newdl = fastai.DataLoaders(models.torchvision.faster_rcnn.fastai.convert_dataloader_to_fastai(train_dl), models.torchvision.faster_rcnn.fastai.convert_dataloader_to_fastai(test_dl)).to(&#39;cuda&#39;) . A continuación modificamos el dataloader del objeto Learn que hemos entrenado anteriormente. . learn.dls = newdl . Por último evaluamos nuestro modelo usando el método validate(). Al igual que en el caso de los modelos de clasificación el método validate() devuelve dos valores, el valor de la pérdida y el valor de la métrica asociada al conjunto de validación, que en este caso es el de test. . learn.validate() . Inferencia . Vamos a ver cómo usar el modelo ante una nueva imagen. Para ello lo primero que vamos a hacer es cargar dicho modelo. Para ello debemos crear un modelo con la arquitectura que utilizamos (Faster RCNN en nuestro caso), y posteriormente cargar el modelo. . model = models.torchvision.faster_rcnn.model(backbone=models.torchvision.faster_rcnn.backbones.resnet18_fpn, num_classes=len(class_map)) state_dict = torch.load(&#39;fasterRCNNFruits.pth&#39;) model.load_state_dict(state_dict) . El siguiente paso es cargar la imagen, para lo que usaremos la librería PIL. . import PIL . img = PIL.Image.open(&#39;fruits/test/images/mixed_25.jpg&#39;) . La siguiente instrucción permite mostrar la imagen que acabamos de cargar. . img . Ya estaríamos listos para relizar las predicciones sobre la imagen. Sin embargo, cabe recordar que primero debemos reescalar las imágenes y normalizarlas. . infer_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size),tfms.A.Normalize()]) . Ya podemos realizar las predicciones mediante el método end2end_detect. Este método, que depende de la arquitectura que hayamos utilizado, recibe como parámetros la imagen sobre la que queremos realizar las predicciones, las transformaciones a aplicar, el modelo (movido a la CPU), el mapa de clases, y el nivel de confianza mínimo para realizar la predicción. . pred_dict = models.torchvision.faster_rcnn.end2end_detect(img, infer_tfms, model.to(&quot;cpu&quot;), class_map=class_map, detection_threshold=0.5) pred_dict[&#39;img&#39;] .",
            "url": "https://ap2122.github.io/aprendizajeprofundo2122/practica/2022/02/20/practica2-deteccion-de-objetos.html",
            "relUrl": "/practica/2022/02/20/practica2-deteccion-de-objetos.html",
            "date": " • Feb 20, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Clasificación de imágenes",
            "content": "En este notebook se muestra cómo crear un modelo de clasificación de imágenes utilizando las técnicas vistas en clase. . Para crear nuestro clasificador de imágenes vamos a utilizar la librería fastAI. Este notebook está inspirado en el curso asociado a dicha librería. . En esta práctica vamos a hacer un uso intensivo de la GPU, así que es importante activar su uso desde la opción Configuración del cuaderno del menú Editar (esta opción debería estar habilitada por defecto, pero es recomendable que lo compruebes). . Librer&#237;as . Comenzamos descargando la última versión de la librería FastAI. Al finalizar la instalación se reiniciará el kernel de manera automática. . !pip install fastai -Uq import IPython IPython.Application.instance().kernel.do_shutdown(True) . A continuación, cargamos aquellas librerías que son necesarias. . from fastai.vision.all import * . Dataset . Para esta práctica vamos a usar como ejemplo de dataset el Intel Image Classification dataset. Este dataset consta de imágenes de tamaño 150x150 distribuidas en 6 categorías (buildings, forest, glacier, mountain, sea, street). Los siguientes comandos descargan y descomprimen dicho dataset. . !wget https://unirioja-my.sharepoint.com/:u:/g/personal/joheras_unirioja_es/EbMVHqKMSnNHh6I0-4-QWdQBlVDKz2Uz5Ky73zc5tHGofg?download=1 -O IntelImageClassification.zip !unzip IntelImageClassification.zip . Vamos a explorar el contenido de este dataset. Para ello vamos a crear un objeto Path que apunta al directorio que acabamos de crear. . path = Path(&#39;IntelImageClassification/&#39;) . Con el objeto path podemos utilizar funciones como ls(). . path.ls() . Vemos que nuestro dataset consta de dos carpetas llamadas train y test. Recordar que es importante hacer la partición del dataset en dos conjuntos distintos, para luego poder evaluarlo correctamente. Podemos ahora crear objetos path que apunten respectivamente a nuestro conjunto de entrenamiento y a nuestro conjunto de test. . trainPath = path/&#39;train&#39; testPath = path/&#39;test&#39; . Veamos el contenido de cada uno de estos directorios. . trainPath.ls() . testPath.ls() . Podemos ver que tanto la carpeta train como la carpeta test contienen 6 subcarpetas, una por cada clase del dataset. . Cargando el dataset . A continuación vamos a mostrar cómo se carga el dataset para poder posteriormente crear nuestro modelo. Este proceso se hace en dos pasos. Primero se construye un objeto DataBlock y a continuación se construye un objeto DataLoader a partir del DataBlock. Tienes más información sobre estos objetos en la documentación de FastAI. . Datablock . Comenzamos construyendo el objeto DataBlock. A continuación explicaremos cada una de sus componentes. . db = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2,seed=42), get_y=parent_label, item_tfms = Resize(256), batch_tfms=aug_transforms(size=128,min_scale=0.75)) . Vamos a ver las distintas componentes del DataBlock. . El atributo blocks sirve para indicar el tipo de nuestros datos. Como estamos en un problema de clasificación de imágenes, tenemos que la entrada de nuestro modelo será una imagen, es decir un ImageBlock, y la salida será una categoría, es decir un CategoryBlock. Por lo tanto indicamos que blocks = (ImageBlock, CategoryBlock). | El atributo get_items debe proporcionar una función para leer los datos. En nuestro caso queremos leer una serie de imágenes que estarán almacenadas en un path. Para ello usamos la función get_image_files. Puedes ver qué hace exactamente esta función ejecutando el comando ??get_image_files. | El atributo splitter nos indica cómo partir el dataset. Daros cuenta que tenemos un conjunto de entrenamiento y uno de test, pero para entrenar nuestro modelo y probar distintas alternativas nos interesa usar un conjunto de validación, que lo vamos a tomar de forma aleatorea a partir de nuestro conjunto de entrenamiento usando un 20% del mismo. Para ello usaremos el objeto RandomSplitter(valid_pct=0.2,seed=42). | El atributo get_y sirve para indicar cómo extraemos la clase a partir de nuestros datos. La función get_image_files nos proporciona una lista con los paths a las imágenes de nuestro dataset. Si nos fijamos en dichos paths, la clase de cada imagen viene dada por la carpeta en la que está contenida, por lo que podemos usar el método parent_label para obtener la clase de la misma. | . Por último, los atributos item_tfms y batch_tfms sirven para aplicar una técnica conocida como preescalado (o presizing). . Preescalado (presizing) . El preescalado es una técnica de aumento de datos diseñada para minimizar la destrucción de datos. Para poder sacar el máximo partido a las GPUs, es necesario que todas las imágenes tengan el mismo tamaño, por lo que es común reescalar todas las imágenes al mismo tamaño. . Sin embargo, hay varias técnicas de aumento que si se aplican después de reescalar pueden introducir zonas vacías o degradar los datos. Por ejemplo, si rotamos una imagen 45 grados, los bordes de la imagen quedan vacíos, lo que no le sirve para nada al modelo. Para solucionar este problema se utiliza la técnica del preescalado que consta de dos pasos. . Las imágenes se reescalan a una dimensión mayor que la que se usará realmente para entrenar. | Se aplican las distintas técnicas de aumento, y finalmente se reescala al tamaño deseado. | El punto clave es el primer paso que sirve para crear imágenes con el suficiente espacio para luego poder aplicar los distintos aumentos. Tienes más información sobre esta técnica en el libro de FastAI. . En nuestro caso estamos haciendo un escalado inicial a tamaño 256 para luego aplicar un escalado a tamaño 128. Notar que no sólo estamos aplicando un escalado como técnica de aumento de datos, sino que también gracias a la función aug_transforms se aplican otros aumentos. . Data augmentation . Como hemos visto en clase, la técnica de aumento de datos (o data augmentation) nos proporciona un método para aumentar el tamaño de nuestro dataset. FastAI ofrece una serie de aumentos por defecto que se pueden configurar mediante el método aug_transforms. Veamos a continuación que aumentos ofrece dicha función. . ??aug_transforms . Como vemos la función anterior puede ser utilizada para fijar distintos aumentos y la probabilidad con la que queremos que se apliquen. En caso de querer otro tipo de transformaciones que no estén incluidas por defecto en dicha función podemos usar la librería Albumentations como se explica en la documentación de FastAI. . Dataloader . Pasamos ahora a construir nuestro DataLoader que se construye a partir del DataBlock construido anteriormente indicándole el path donde se encuentran nuestras imágenes. Además podemos configurar el DataLoader indicándole el tamaño del batch que queremos utilizar. Al trabajar con GPUs es importante que usemos batches de tamaño 2^n para optimizar el uso de la GPU. . dls = db.dataloaders(trainPath,bs=128) . A continuación mostramos un batch de nuestro DataLoader. Es conveniente comprobar que realmente se han cargado las imágenes y sus anotaciones de manera correcta. . dls.show_batch() . Entrenando el modelo . Pasamos ahora a construir y entrenar nuestro modelo. Pero antes vamos a definir una serie de callbacks. . Callbacks . En ocasiones nos interesa cambiar el comportamiento por defecto que tiene el proceso de entrenamiento, por ejemplo para guardar los mejores pesos que se han producido hasta ese momento. El procedimiento usado por FastAI para incluir dicha funcionalidad son los callbacks que sirven para modificar el proceso de entrenamiento. La lista completa de callbacks incluida en FastAI, está disponible en su documentación. En nuesto caso sólo vamos a utilizar 3 callbacks: . ShowGraphCallback: este callback sirve para mostrar las curvas de entrenamiento y validación. | EarlyStoppingCallback: este callback nos permite aplicar la técnica de early stopping. Para ello debemos indicarle la métrica que queremos monitorizar para saber cuándo parar, y la paciencia (es decir cuántas épocas dejamos que el modelo continúe entrenando si no ha habido mejora). | SaveModelCallback: este callback guarda el mejor modelo encontrado durante el proceso de entrenamiento y lo carga al final del mismo. Como vamos a crear un modelo usando la arquitectura resnet18 conviene que indiquemos esto en el nombre del modelo. También sería conveniente indicar el nombre del dataset para no confundirlos. | . callbacks = [ ShowGraphCallback(), EarlyStoppingCallback(patience=3), SaveModelCallback(fname=&#39;modelResnet18&#39;) ] . Además de estos tres callbacks utilizaremos otro que nos servirá para acelerar el entrenamiento de nuestros modelos usando mixed precision. . Construyendo el modelo . A continuación construimos nuestro modelo, un objeto de la clase Learner, utilizando el método cnn_learner que toma como parámetros el DataLoader, la arquitectura que queremos entrenar (en nuestro caso un resnet18), la métrica que usaremos para evaluar nuestro modelo (esta evaluación se hace sobre el conjunto de validación, y en nuestro caso será la accuracy), y los callbacks. Notar que en la instrucción anterior incluimos la transformación del modelo a mixed precision. . learn = cnn_learner(dls,resnet18,metrics=accuracy,cbs=callbacks).to_fp16() . Notar que internamente la función cnn_learner hace varias cosas con la arquitectura que le pasamos como parámetro (en este caso resnet18). Dicha arquitectura fue entrenada inicialmente para el problema de ImageNet, por lo que ante una nueva imagen, su salida sería la predicción en una de las 1000 clases de ImageNet. Sin embargo, internamente la función cnn_learner elimina las últimas capas de dicha arquitectura, y las reemplaza con una adecuada para nuestro problema concreto. . Antes de entrenar nuestro modelo debemos encontrar un learning rate adecuado. . Learning rate finder . Como hemos visto en teoría, el trabajo de Leslie Smith proporciona un método para encontrar un learning rate adecuado para entrenar nuestro modelo. Dicho learning rate lo puedes encontrar con la función lr_find(). . learn.lr_find() . La función anterior no solo nos devuelve un gráfico sino que nos sugiere dos valores lr_min y lr_steep. La recomendación es utilizar el valor de lr_steep, para entrenar el modelo. . Fine-tuning . A continuación vamos a aplicar la técnica de fine tuning. En FastAI esto es tan sencillo como llamar al método fine_tune del objeto Learner. Este método recibe dos parámetros principalmente, el número de épocas (10 en nuestro caso) y el learning rate. El proceso que sigue para entrenar consiste en: . Congelar todas las capas salvo la última, y entrenar esa parte del modelo durante una época. | Descongelar la red, y entrenar el modelo por el número de épocas indicado. | Al ejecutar la siguiente instrucción aparecerá una tabla donde podrás ver la pérdida para el conjunto de entrenamiento, la pérdida para el conjunto de validación, y la accuracy para el conjunto de validación. . learn.fine_tune(10,base_lr=1e-3) . Al final del entrenamiento se ha guardado un modelo en la carpeta models que contiene el mejor modelo construido. . Path(&#39;models&#39;).ls() . Para su uso posterior, es conveniente exportar el modelo. Para ello es necesario en primer lugar convertir el modelo a fp32. . learn.to_fp32() learn.export() . Podemos ver que dicho modelo se ha guardado en el mismo directorio donde nos encontramos. . Path().ls(file_exts=&#39;.pkl&#39;) . Evaluando el modelo . Una vez tenemos entrenado nuestro modelo nos interesa saber: . ¿Qué tal funciona en el conjunto de test? | ¿Qué errores comete? | ¿Cómo se utiliza para predecir la clase ante nuevas imágenes? | Evaluando el modelo en el conjunto de test . Para poder evaluar nuestro modelo en el conjunto de test debemos crear un nuevo DataBlock y un nuevo DataLoader. La única diferencia con el DataBlock utilizado previamente es que para hacer la partición del dataset usamos un objeto de la clase GrandparentSplitter indicando que el conjunto de validación es nuestro conjunto de test. En el caso del DataLoader, la diferencia con el definido anteriormente es que cambiamos la ruta al path. . dbTest = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items=get_image_files, splitter=GrandparentSplitter(valid_name=&#39;test&#39;), get_y=parent_label, item_tfms = Resize(256), batch_tfms=aug_transforms(size=128,min_scale=0.75)) dlsTest = dbTest.dataloaders(path,bs=128) . Para trabajar con este dataloader debemos modificar nuestro objeto Learner. En concreto su atributo dls. . learn.dls = dlsTest . Ahora podemos evaluar nuestro modelo usando el método validate. . learn.validate() . El método validate nos devuelve dos valores: el valor de la función de pérdida, y el valor de nuestra métrica (la accuracy en este caso). Por lo que podemos ver que el modelo tiene una accuracy en el conjunto de test de aproximadamente un 82% (esto puede variar dependiendo de la ejecución). . Interpretaci&#243;n del modelo . Hemos visto que nuestro modelo obtiene una accuracy aproximada (puede variar debido a la aleatoriedad del proceso de entrenamiento) de un 92% en el conjunto de validación. Pero nos interesa conocer los errores que se cometen y si estos son razonables. Para ello podemos construir un objeto ClassificationInterpretation a partir de nuestro Learner y mostrar la matriz de confusión asociada. Recordar que hemos cambiado el DataLoader en el paso anterior, porque es conveniente volver al dataloader usado inicialmente. . learn.dls=dls . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12),dpi=60) . Si nos fijamos, la mayoría de errores se producen porque el modelo confunde imágenes de la clase street con imágenes de la clase buildings; e imágenes de la clase mountain con la clase glacier. Podemos ver aquellas en las que se produce un mayor error del siguiente modo. Normalmente utilizaríamos el comando interp.plot_top_losses(10,nrows=2), pero como se muestra en el foro de FastAI, esto produce un comportamiento anómalo que será corregido en próximas versiones, por lo que tenemos que usar la solución que proporcionan en dicho hilo que consiste en definir la siguiente función. . def plot_top_losses_fix(interp, k, largest=True, **kwargs): losses,idx = interp.top_losses(k, largest) if not isinstance(interp.inputs, tuple): interp.inputs = (interp.inputs,) if isinstance(interp.inputs[0], Tensor): inps = tuple(o[idx] for o in interp.inputs) else: inps = interp.dl.create_batch(interp.dl.before_batch([tuple(o[i] for o in interp.inputs) for i in idx])) b = inps + tuple(o[idx] for o in (interp.targs if is_listy(interp.targs) else (interp.targs,))) x,y,its = interp.dl._pre_show_batch(b, max_n=k) b_out = inps + tuple(o[idx] for o in (interp.decoded if is_listy(interp.decoded) else (interp.decoded,))) x1,y1,outs = interp.dl._pre_show_batch(b_out, max_n=k) if its is not None: #plot_top_losses(x, y, its, outs.itemgot(slice(len(inps), None)), L(self.preds).itemgot(idx), losses, **kwargs) plot_top_losses(x, y, its, outs.itemgot(slice(len(inps), None)), interp.preds[idx], losses, **kwargs) #TODO: figure out if this is needed #its None means that a batch knows how to show itself as a whole, so we pass x, x1 #else: show_results(x, x1, its, ctxs=ctxs, max_n=max_n, **kwargs) . Una vez definida dicha función ya podemos ver los mayores errores. . interp.plot_top_losses(10,nrows=2) . A partir de la ejecución anterior, podemos ver que hay algunas imágenes que están mal anotadas, y otras en las que es comprensible por qué se está produciendo el error. . Usando el modelo . Vamos a ver cómo usar el modelo ante una nueva imagen. Para ello lo primero que vamos a hacer es cargar dicho modelo. . learn_inf = load_learner(&#39;export.pkl&#39;) . Ahora podemos usar dicho modelo para hacer inferencia con una nueva imagen mediante el método predict. En nuestro caso vamos a usar una imagen del conjunto de test. . learn_inf.predict(&#39;IntelImageClassification/test/buildings/20057.jpg&#39;) . La función anterior devuelve tres valores: . La clase (buildings en este caso). | El índice asociado a dicha clase. | Las probabilidades para cada una de las categorías. | . Creando una aplicaci&#243;n para nuestro modelo . Es fundamental que los modelos sean usables, por lo que es conveniente proporcionar una interfaz secilla que permita usar nuestros modelos. Para ello, vamos a usar dos herramientas: Gradio y los espacios de HuggingFace. En concreto vamos a ver cómo construir la siguiente aplicación siguiendo los pasos del blog de Tanishq Abraham. . Para crear nuestra aplicación vamos a seguir los siguientes pasos: . Descarga el fichero export.pkl creado anteriormente. | Descarga dos de las imágenes del dataset. | Crea una cuenta en HuggingFace. Este paso sólo hay que realizarlo una vez. | Crea un espacio en HuggingFace. Al crear dicho espacio usamos como nombre Practica1 y seleccionamos Gradio como SDK. | Una vez creado el espacio vamos a la pestaña Files and versions. En dicha pestaña debemos: Subir el fichero export.pkl mediante el botón Add file -&gt; Upload file. | Sube las dos imágenes que hayas descargado mediante el botón Add file -&gt; Upload file. | Crear un fichero requirements.txt mediante el botón Add file -&gt; Create a new file. Este fichero contendrá las librerías que son necesarias instalar para ejecutar nuestra aplicación, en este caso fastai. | Crear un fichero app.py mediante el botón Add file -&gt; Create a new file. Este fichero contendrá el código de la aplicación. | . | Siguiendo estos pasos tendrás una aplicación que podrás ver desde la pestaña App (la construcción de la aplicación puede llevar unos segundos, el proceso de construcción lo podrás ver pulsando en el botón See logs. |",
            "url": "https://ap2122.github.io/aprendizajeprofundo2122/practica/2022/01/10/practica1-clasificacion-imagenes.html",
            "relUrl": "/practica/2022/01/10/practica1-clasificacion-imagenes.html",
            "date": " • Jan 10, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Página creada por Jónathan Heras. .",
          "url": "https://ap2122.github.io/aprendizajeprofundo2122/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ap2122.github.io/aprendizajeprofundo2122/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}